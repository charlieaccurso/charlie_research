{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f20248c",
   "metadata": {},
   "source": [
    "Manually classify the working language and embedded language of the first 100 posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88263091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db1a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_length(conversation_id):\n",
    "    \"\"\"\n",
    "    Get the total number of posts given a conversation_id\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include only rows with the given conversation_id\n",
    "    filtered_df = df[df['conversation_id'] == conversation_id]\n",
    "    \n",
    "    # Get the total number of posts for the conversation_id\n",
    "    total_posts = len(filtered_df)\n",
    "    \n",
    "    return total_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c75a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_post(post, n):\n",
    "    \"\"\"\n",
    "    Truncate a string to a maximum number of tokens (n)\n",
    "    \"\"\"\n",
    "    # Tokenize the input string into words\n",
    "    words = word_tokenize(post)\n",
    "    \n",
    "    # Select the first n tokens\n",
    "    truncated_tokens = words[:n]\n",
    "    \n",
    "    # Join the selected tokens back into a string\n",
    "    truncated_post = ' '.join(truncated_tokens)\n",
    "    \n",
    "    return truncated_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b67411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"conv_sample_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de4b55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Examining data point 10, with conversation_id 3\n",
      "----Data point 10 is part of a conversation of length 20\n",
      "--------Post content: `` Ca n't Rename , no element found '' on anything I try to rename\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 10 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 11, with conversation_id 3\n",
      "----Data point 11 is part of a conversation of length 20\n",
      "--------Post content: Has clojure-lsp started correctly ?\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 11 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 12, with conversation_id 3\n",
      "----Data point 12 is part of a conversation of length 20\n",
      "--------Post content: > Has clojure-lsp started correctly ? Yes\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 12 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 13, with conversation_id 3\n",
      "----Data point 13 is part of a conversation of length 20\n",
      "--------Post content: What do you get in the clojure-lsp server log ? Also see if the message trace log . You can reach the server log via\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 13 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 14, with conversation_id 3\n",
      "----Data point 14 is part of a conversation of length 20\n",
      "--------Post content: Clojure-lsp log `` ` 2022-11-20T20:58:18.659Z INFO [ clojure-lsp.handlers:253 ] - : document-highlight 0ms 2022-11-20T20:58:18.661Z INFO [ clojure-lsp.handlers:410 ] - : code-actions 2ms 2022-11-20T20:58:18.875Z INFO [\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 14 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 15, with conversation_id 3\n",
      "----Data point 15 is part of a conversation of length 20\n",
      "--------Post content: Does this happen only in a specific project or any project ? CC @ ericdallo\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 15 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 16, with conversation_id 3\n",
      "----Data point 16 is part of a conversation of length 20\n",
      "--------Post content: No , it happens on a fresh lein app project as well\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 16 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 17, with conversation_id 3\n",
      "----Data point 17 is part of a conversation of length 20\n",
      "--------Post content: It could be that the VS Code install has issues . Can you try with VS Code Insiders and see if the problem is there\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 17 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 18, with conversation_id 3\n",
      "----Data point 18 is part of a conversation of length 20\n",
      "--------Post content: [ This ] ( https : //github.com/clojure-lsp/clojure-lsp/blob/master/lib/src/clojure_lsp/feature/rename.clj # L194 ) is the check clojure-lsp does to allow renaming and the message usually is pretty clear\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 18 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 19, with conversation_id 3\n",
      "----Data point 19 is part of a conversation of length 20\n",
      "--------Post content: This is happening on two different windows computers , btw > [ This ] ( https : //github.com/clojure-lsp/clojure-lsp/blob/master/lib/src/clojure_lsp/feature/rename.clj # L194 ) is the check clojure-lsp\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 19 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 20, with conversation_id 3\n",
      "----Data point 20 is part of a conversation of length 20\n",
      "--------Post content: @ crimsonhawk47 do you remember roughly when it used to work ? Could be a change in Calva that trips it up . So you\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 20 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 21, with conversation_id 3\n",
      "----Data point 21 is part of a conversation of length 20\n",
      "--------Post content: > @ crimsonhawk47 do you remember roughly when it used to work ? Could be a change in Calva that trips it up . So\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 21 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 22, with conversation_id 3\n",
      "----Data point 22 is part of a conversation of length 20\n",
      "--------Post content: Thanks , @ crimsonhawk47 ! Have you tried with different versions of clojure-lsp ?\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 22 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 23, with conversation_id 3\n",
      "----Data point 23 is part of a conversation of length 20\n",
      "--------Post content: also , is there a sample project ?\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 23 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 24, with conversation_id 3\n",
      "----Data point 24 is part of a conversation of length 20\n",
      "--------Post content: > Thanks , @ crimsonhawk47 ! Have you tried with different versions of clojure-lsp ? It looks like the previous version of clojure-lsp makes this\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 24 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 25, with conversation_id 3\n",
      "----Data point 25 is part of a conversation of length 20\n",
      "--------Post content: Let 's keep this issue open for discoverability . @ crimsonhawk47 I can recommend giving it a go to fix the issue ( without knowing\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 25 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 26, with conversation_id 3\n",
      "----Data point 26 is part of a conversation of length 20\n",
      "--------Post content: This should be fixed on clojure-lsp master\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 26 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 27, with conversation_id 3\n",
      "----Data point 27 is part of a conversation of length 20\n",
      "--------Post content: Hurray ! Thanks @ ericdallo ! Does fixed on master mean it can be tested with the ` nightly ` clojure-lsp setting in Calva ?\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 27 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 28, with conversation_id 3\n",
      "----Data point 28 is part of a conversation of length 20\n",
      "--------Post content: Yes @ PEZ\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 28 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 29, with conversation_id 3\n",
      "----Data point 29 is part of a conversation of length 20\n",
      "--------Post content: Going to close this since it 's merged to master and the upstream issue is closed now . @ crimsonhawk47 If you still have the\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 29 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 30, with conversation_id 4\n",
      "----Data point 30 is part of a conversation of length 1\n",
      "--------Post content: < ! -- CLA-CHECK:130 -- > & # 10060 ; Author of the following commits did not sign a [ Contributor Agreement ] ( https\n",
      "--------Getting the language classification...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 30 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 31, with conversation_id 5\n",
      "----Data point 31 is part of a conversation of length 1\n",
      "--------Post content: Bump engine.io and browser-sync . Bumps [ engine.io ] ( https : //github.com/socketio/engine.io ) to 6.2.1 and updates ancestor dependency [ browser-sync ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 31 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 32, with conversation_id 6\n",
      "----Data point 32 is part of a conversation of length 1\n",
      "--------Post content: Bump pillow from 6.0.0 to 9.3.0 . Bumps [ pillow ] ( https : //github.com/python-pillow/Pillow ) from 6.0.0 to 9.3.0 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 32 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 33, with conversation_id 7\n",
      "----Data point 33 is part of a conversation of length 1\n",
      "--------Post content: Bump sentry-sdk from 1.9.5 to 1.11.1 . Bumps [ sentry-sdk ] ( https : //github.com/getsentry/sentry-python ) from 1.9.5 to 1.11.1 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 33 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 34, with conversation_id 8\n",
      "----Data point 34 is part of a conversation of length 39\n",
      "--------Post content: @ bors try @ rust-timer queue\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 34 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 35, with conversation_id 8\n",
      "----Data point 35 is part of a conversation of length 39\n",
      "--------Post content: Awaiting bors try build completion . @ rustbot label : +S-waiting-on-perf\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 35 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 36, with conversation_id 8\n",
      "----Data point 36 is part of a conversation of length 39\n",
      "--------Post content: : hourglass : Trying commit e76574c786b189e49aeb4965239fb1d46176b017 with merge b024321c74e3e2606191ceaea34c201cf4f42c25 ... < ! -- homu : { `` type '' : '' TryBuildStarted '' , ''\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 36 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 37, with conversation_id 8\n",
      "----Data point 37 is part of a conversation of length 39\n",
      "--------Post content: : sunny : Try build successful - [ checks-actions ] ( https : //github.com/rust-lang-ci/rust/actions/runs/3381089377/jobs/5616435202 ) Build commit : b024321c74e3e2606191ceaea34c201cf4f42c25 ( ` b024321c74e3e2606191ceaea34c201cf4f42c25 ` ) <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 37 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 38, with conversation_id 8\n",
      "----Data point 38 is part of a conversation of length 39\n",
      "--------Post content: Queued b024321c74e3e2606191ceaea34c201cf4f42c25 with parent edf0182213a9e30982eb34f3925ddc4cf5ed3471 , future [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=edf0182213a9e30982eb34f3925ddc4cf5ed3471 & end=b024321c74e3e2606191ceaea34c201cf4f42c25 ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 38 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 39, with conversation_id 8\n",
      "----Data point 39 is part of a conversation of length 39\n",
      "--------Post content: Finished benchmarking commit ( b024321c74e3e2606191ceaea34c201cf4f42c25 ) : [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=edf0182213a9e30982eb34f3925ddc4cf5ed3471 & end=b024321c74e3e2606191ceaea34c201cf4f42c25 & stat=instructions : u ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 39 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 40, with conversation_id 8\n",
      "----Data point 40 is part of a conversation of length 39\n",
      "--------Post content: Hmm ... maybe I need to do the `` erase const effects '' stuff after all\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 40 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 41, with conversation_id 8\n",
      "----Data point 41 is part of a conversation of length 39\n",
      "--------Post content: @ bors try @ rust-timer queue\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 41 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 42, with conversation_id 8\n",
      "----Data point 42 is part of a conversation of length 39\n",
      "--------Post content: Awaiting bors try build completion . @ rustbot label : +S-waiting-on-perf\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 42 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 43, with conversation_id 8\n",
      "----Data point 43 is part of a conversation of length 39\n",
      "--------Post content: : hourglass : Trying commit b0cadfe19e87de8eef09bc55ffb0af302d1b8321 with merge 05135c4c1e525688413ed9f23d48008733f8911f ... < ! -- homu : { `` type '' : '' TryBuildStarted '' , ''\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 43 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 44, with conversation_id 8\n",
      "----Data point 44 is part of a conversation of length 39\n",
      "--------Post content: : sunny : Try build successful - [ checks-actions ] ( https : //github.com/rust-lang-ci/rust/actions/runs/3384541892/jobs/5623788533 ) Build commit : 05135c4c1e525688413ed9f23d48008733f8911f ( ` 05135c4c1e525688413ed9f23d48008733f8911f ` ) <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 44 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 45, with conversation_id 8\n",
      "----Data point 45 is part of a conversation of length 39\n",
      "--------Post content: Queued 05135c4c1e525688413ed9f23d48008733f8911f with parent 432b1a427710223b31f65585c352796832af8aa7 , future [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=432b1a427710223b31f65585c352796832af8aa7 & end=05135c4c1e525688413ed9f23d48008733f8911f ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 45 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 46, with conversation_id 8\n",
      "----Data point 46 is part of a conversation of length 39\n",
      "--------Post content: Finished benchmarking commit ( 05135c4c1e525688413ed9f23d48008733f8911f ) : [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=432b1a427710223b31f65585c352796832af8aa7 & end=05135c4c1e525688413ed9f23d48008733f8911f & stat=instructions : u ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 46 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 47, with conversation_id 8\n",
      "----Data point 47 is part of a conversation of length 39\n",
      "--------Post content: looks like the perf regression is just inlining noise from tracing instrumentation . Removed that @ bors try @ rust-timer queue\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 47 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 48, with conversation_id 8\n",
      "----Data point 48 is part of a conversation of length 39\n",
      "--------Post content: Awaiting bors try build completion . @ rustbot label : +S-waiting-on-perf\n",
      "--------Getting the language classification...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 48 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 49, with conversation_id 8\n",
      "----Data point 49 is part of a conversation of length 39\n",
      "--------Post content: : hourglass : Trying commit 7738cc734546bc91ede24376970cc4dfd01580da with merge 4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 ... < ! -- homu : { `` type '' : '' TryBuildStarted '' , ''\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 49 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 50, with conversation_id 8\n",
      "----Data point 50 is part of a conversation of length 39\n",
      "--------Post content: : sunny : Try build successful - [ checks-actions ] ( https : //github.com/rust-lang-ci/rust/actions/runs/3387025807/jobs/5629370226 ) Build commit : 4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 ( ` 4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 ` ) <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 50 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 51, with conversation_id 8\n",
      "----Data point 51 is part of a conversation of length 39\n",
      "--------Post content: Queued 4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 with parent 160b19429523ea44c4c3b7cad4233b2a35f58b8f , future [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=160b19429523ea44c4c3b7cad4233b2a35f58b8f & end=4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 51 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 52, with conversation_id 8\n",
      "----Data point 52 is part of a conversation of length 39\n",
      "--------Post content: Finished benchmarking commit ( 4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 ) : [ comparison URL ] ( https : //perf.rust-lang.org/compare.html ? start=160b19429523ea44c4c3b7cad4233b2a35f58b8f & end=4997a56cf2edc4b2be488f2f2b586bf5e2bb3b37 & stat=instructions : u ) .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 52 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 53, with conversation_id 8\n",
      "----Data point 53 is part of a conversation of length 39\n",
      "--------Post content: The job * * ` mingw-check ` * * failed ! Check out the build log : [ ( web ) ] ( https :\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 53 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 54, with conversation_id 8\n",
      "----Data point 54 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 103991 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 54 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 55, with conversation_id 8\n",
      "----Data point 55 is part of a conversation of length 39\n",
      "--------Post content: For the tidy limit , I was wondering if we could split it into two limits , one for files and the other for directories\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 55 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 56, with conversation_id 8\n",
      "----Data point 56 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 104138 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 56 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 57, with conversation_id 8\n",
      "----Data point 57 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 103171 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 57 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 58, with conversation_id 8\n",
      "----Data point 58 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 104215 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 58 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 59, with conversation_id 8\n",
      "----Data point 59 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 104555 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 59 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 60, with conversation_id 8\n",
      "----Data point 60 is part of a conversation of length 39\n",
      "--------Post content: > ` mk_subst_trait_with_effect ` is n't great , maybe ` mk_trait_ref_with_effect ` would be better , rn we duplicate the trait ` DefId ` vscode\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 60 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 61, with conversation_id 8\n",
      "----Data point 61 is part of a conversation of length 39\n",
      "--------Post content: The job * * ` mingw-check ` * * failed ! Check out the build log : [ ( web ) ] ( https :\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > Englist\n",
      "--------Classification is: Englist\n",
      "--------The language(s) used in data point 61 are: {'Englist'}\n",
      "\n",
      "\n",
      "• Examining data point 62, with conversation_id 8\n",
      "----Data point 62 is part of a conversation of length 39\n",
      "--------Post content: The job * * ` mingw-check ` * * failed ! Check out the build log : [ ( web ) ] ( https :\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 62 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 63, with conversation_id 8\n",
      "----Data point 63 is part of a conversation of length 39\n",
      "--------Post content: A job failed ! Check out the build log : [ ( web ) ] ( https : //github.com/rust-lang/rust/actions/runs/3532861958/jobs/5927747791 ) [ ( plain ) ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 63 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 64, with conversation_id 8\n",
      "----Data point 64 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 104776 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 64 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 65, with conversation_id 8\n",
      "----Data point 65 is part of a conversation of length 39\n",
      "--------Post content: @ rustbot ready @ lcnr\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 65 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 66, with conversation_id 8\n",
      "----Data point 66 is part of a conversation of length 39\n",
      "--------Post content: Some changes occurred to MIR optimizations cc @ rust-lang/wg-mir-opt Hey ! It looks like you 've submitted a new PR for the library teams !\n",
      "--------Getting the language classification...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 66 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 67, with conversation_id 8\n",
      "----Data point 67 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 105183 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 67 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 68, with conversation_id 8\n",
      "----Data point 68 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 105644 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 68 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 69, with conversation_id 8\n",
      "----Data point 69 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 105612 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 69 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 70, with conversation_id 8\n",
      "----Data point 70 is part of a conversation of length 39\n",
      "--------Post content: : umbrella : The latest upstream changes ( presumably # 105979 ) made this pull request unmergeable . Please [ resolve the merge conflicts ]\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 70 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 71, with conversation_id 8\n",
      "----Data point 71 is part of a conversation of length 39\n",
      "--------Post content: If I am correct this can be switched to waiting on author . Feel free to request a review with ` @ rustbot ready `\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 71 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 72, with conversation_id 8\n",
      "----Data point 72 is part of a conversation of length 39\n",
      "--------Post content: This PR has become impossible to rebase . I 'm starting from scratch on a new branch with a smaller MVP\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 72 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 73, with conversation_id 9\n",
      "----Data point 73 is part of a conversation of length 5\n",
      "--------Post content: Successfully deployed to the following URLs : # # examples-svelte-web – ./examples/with-svelte/apps/web [ examples-svelte-web.vercel.sh ] ( https : //examples-svelte-web.vercel.sh ) [ examples-svelte-web-git-main.vercel.sh ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 73 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 74, with conversation_id 9\n",
      "----Data point 74 is part of a conversation of length 5\n",
      "--------Post content: Successfully deployed to the following URLs : # # examples-nonmonorepo – ./examples/non-monorepo [ examples-nonmonorepo-git-main.vercel.sh ] ( https : //examples-nonmonorepo-git-main.vercel.sh ) [ examples-nonmonorepo.vercel.sh ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 74 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 75, with conversation_id 9\n",
      "----Data point 75 is part of a conversation of length 5\n",
      "--------Post content: Successfully deployed to the following URLs : # # examples-designsystem-docs – ./examples/design-system/apps/docs [ examples-designsystem-docs.vercel.sh ] ( https : //examples-designsystem-docs.vercel.sh ) [ examples-designsystem-docs-git-main.vercel.sh ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 75 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 76, with conversation_id 9\n",
      "----Data point 76 is part of a conversation of length 5\n",
      "--------Post content: Successfully deployed to the following URLs : # # examples-kitchensink-blog – ./examples/kitchen-sink/apps/blog [ examples-kitchensink-blog-git-main.vercel.sh ] ( https : //examples-kitchensink-blog-git-main.vercel.sh ) [ examples-kitchensink-blog.vercel.sh ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 76 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 77, with conversation_id 9\n",
      "----Data point 77 is part of a conversation of length 5\n",
      "--------Post content: Successfully deployed to the following URLs : # # examples-native-web – ./examples/with-react-native-web/apps/web [ examples-native-web-git-main.vercel.sh ] ( https : //examples-native-web-git-main.vercel.sh ) [ examples-native-web.vercel.sh ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 77 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 78, with conversation_id 10\n",
      "----Data point 78 is part of a conversation of length 2\n",
      "--------Post content: Too mant 'stable ' releases . Six 'stable ' releases in six weeks . How can you call them stable ? How about -rc versions\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 78 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 79, with conversation_id 10\n",
      "----Data point 79 is part of a conversation of length 2\n",
      "--------Post content: They are pros , of course . Thanks for sharing your concerns .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 79 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 80, with conversation_id 11\n",
      "----Data point 80 is part of a conversation of length 1\n",
      "--------Post content: 女朋友说来大姨妈怎么回复暖心的话 高清在线 . 女朋友说来大姨妈怎么回复暖心的话 “ 这么着急想要扑倒我么～ ” 沧笙伸手就把采蝶接住了，奶香奶昔的味道瞬间传入沧笙鼻中，令她心里瞬间柔软片刻，忍不住抬手，轻轻摸了摸采蝶柔软的发丝。弱的能量都只有一点点，如同鸡肋。女朋友说来大姨妈怎么回复暖心的话 高清在线 “ 只是死人复活还是尸体，但忘记前尘往事的叫醒尸罢了。 ” 月清看了麟捷一眼，不紧不慢说到，沧笙 “ 哦 ” 了一声，将探出去去的身影收了回来。如温，还是叫你笙舞好呢，还是不告诉你了，你的故事中从未提到过我，想必是我让你失望了，如果现在提起，也只会让你好不容易隐藏起来的痛，越发疼痛。 [ * * -- 》点击进入看日韩午夜大片 -- 》点击进入看日韩午夜大片 *\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > Chinese Simplified\n",
      "--------Classification is: Chinese Simplified\n",
      "--------The language(s) used in data point 80 are: {'Chinese Simplified'}\n",
      "\n",
      "\n",
      "• Examining data point 81, with conversation_id 12\n",
      "----Data point 81 is part of a conversation of length 1\n",
      "--------Post content: Superseded by # 198 .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 81 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 82, with conversation_id 13\n",
      "----Data point 82 is part of a conversation of length 1\n",
      "--------Post content: Bump loader-utils and @ angular-devkit/build-angular in /ng-dashboard . Bumps [ loader-utils ] ( https : //github.com/webpack/loader-utils ) to 3.2.1 and updates ancestor dependency [ @\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 82 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 83, with conversation_id 14\n",
      "----Data point 83 is part of a conversation of length 1\n",
      "--------Post content: Bump loader-utils and webpack-cli . Bumps [ loader-utils ] ( https : //github.com/webpack/loader-utils ) and [ webpack-cli ] ( https : //github.com/webpack/webpack-cli ) . These\n",
      "--------Getting the language classification...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 83 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 84, with conversation_id 15\n",
      "----Data point 84 is part of a conversation of length 1\n",
      "--------Post content: MQ Smoke test PR . autogenerated pr\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 84 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 85, with conversation_id 16\n",
      "----Data point 85 is part of a conversation of length 1\n",
      "--------Post content: [ Snyk ] Upgrade snyk from 1.996.0 to 1.1044.0 . < h3 > Snyk has created this PR to upgrade snyk from 1.996.0 to 1.1044.0.\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 85 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 86, with conversation_id 17\n",
      "----Data point 86 is part of a conversation of length 1\n",
      "--------Post content: [ Witness ] JKU-INS : go.sum database tree @ 9472793\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 86 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 87, with conversation_id 18\n",
      "----Data point 87 is part of a conversation of length 1\n",
      "--------Post content: Add database functionality . Add the functionality to store the number of messages a user has sent in a server to the Discord bot .\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 87 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 88, with conversation_id 19\n",
      "----Data point 88 is part of a conversation of length 1\n",
      "--------Post content: Successfully deployed to the following URLs : # # media-flags – ./ [ media-flags.vercel.app ] ( https : //media-flags.vercel.app ) [ media-flags-respectad1k.vercel.app ] ( https\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 88 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 89, with conversation_id 20\n",
      "----Data point 89 is part of a conversation of length 1\n",
      "--------Post content: Bump certifi from 2019.6.16 to 2022.12.7 . Bumps [ certifi ] ( https : //github.com/certifi/python-certifi ) from 2019.6.16 to 2022.12.7 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 89 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 90, with conversation_id 21\n",
      "----Data point 90 is part of a conversation of length 3\n",
      "--------Post content: [ RND-402 ] Standardize the logging\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 90 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 91, with conversation_id 21\n",
      "----Data point 91 is part of a conversation of length 3\n",
      "--------Post content: Lines 62 and 67should also be errors instead of debug messages ( I was n't able to add a suggestion for those lines )\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 91 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 92, with conversation_id 21\n",
      "----Data point 92 is part of a conversation of length 3\n",
      "--------Post content: I agree about this specific line - it should be an error , because we do n't really know what happened , and had to\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 92 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 93, with conversation_id 22\n",
      "----Data point 93 is part of a conversation of length 2\n",
      "--------Post content: feat : check-kotlin-gradle에 sonar-token input 추가 . # # Proposed Changes secret명이 항상 SONAR_TOKEN이 아닌 경우 ( 저장소에 하나 이상의 패키지가 있을때 ) 에 input으로\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > Korean\n",
      "--------Classification is: Korean\n",
      "--------The language(s) used in data point 93 are: {'Korean'}\n",
      "\n",
      "\n",
      "• Examining data point 94, with conversation_id 22\n",
      "----Data point 94 is part of a conversation of length 2\n",
      "--------Post content: 그럼 required는 빼야 하지 않을까요 ?\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > Korean\n",
      "--------Classification is: Korean\n",
      "--------The language(s) used in data point 94 are: {'Korean'}\n",
      "\n",
      "\n",
      "• Examining data point 95, with conversation_id 23\n",
      "----Data point 95 is part of a conversation of length 1\n",
      "--------Post content: Bump qs and express . Bumps [ qs ] ( https : //github.com/ljharb/qs ) and [ express ] ( https : //github.com/expressjs/express ) . These\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 95 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 96, with conversation_id 24\n",
      "----Data point 96 is part of a conversation of length 1\n",
      "--------Post content: Bump qs from 6.5.2 to 6.5.3 . Bumps [ qs ] ( https : //github.com/ljharb/qs ) from 6.5.2 to 6.5.3 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 96 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 97, with conversation_id 25\n",
      "----Data point 97 is part of a conversation of length 1\n",
      "--------Post content: Bump qs from 6.5.2 to 6.5.3 . Bumps [ qs ] ( https : //github.com/ljharb/qs ) from 6.5.2 to 6.5.3 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 97 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 98, with conversation_id 26\n",
      "----Data point 98 is part of a conversation of length 1\n",
      "--------Post content: Bump qs from 6.5.2 to 6.5.3 . Bumps [ qs ] ( https : //github.com/ljharb/qs ) from 6.5.2 to 6.5.3 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 98 are: {'English'}\n",
      "\n",
      "\n",
      "• Examining data point 99, with conversation_id 27\n",
      "----Data point 99 is part of a conversation of length 1\n",
      "--------Post content: Bump express from 4.16.4 to 4.17.3 . Bumps [ express ] ( https : //github.com/expressjs/express ) from 4.16.4 to 4.17.3 . < details > <\n",
      "--------Getting the language classification...\n",
      "Classify this post as: > English\n",
      "--------Classification is: English\n",
      "--------The language(s) used in data point 99 are: {'English'}\n",
      "\n",
      "\n",
      "DataFrame has been saved to conv_sample_posts.csv\n"
     ]
    }
   ],
   "source": [
    "# iterate through a range of conversation data points\n",
    "for i in range(10, 100):\n",
    "    \n",
    "    conversation_id= df.at[i, 'conversation_id']\n",
    "    print(f\"• Examining data point {i}, with conversation_id {conversation_id}\")\n",
    "    \n",
    "    if pd.isna(df['post_working_language_actual'].iloc[i]):\n",
    "\n",
    "        # see how long the conversation is\n",
    "        conversation_length= get_conversation_length(conversation_id)\n",
    "        print(f\"----Data point {i} is part of a conversation of length {conversation_length}\")\n",
    "\n",
    "        # initialize a set to store the languages associated with the post\n",
    "        languages= set()\n",
    "\n",
    "        # get the post content\n",
    "        post= df.at[i, 'post']\n",
    "        # truncate the post\n",
    "        truncated_post= truncate_post(post, 25)\n",
    "\n",
    "        # print out the truncated post\n",
    "        print(f\"--------Post content: {truncated_post}\")\n",
    "\n",
    "        # get the language classification for the text\n",
    "        print(f\"--------Getting the language classification...\")\n",
    "        classification= input(\"Classify this post as: > \") # <- HERE IS WHERE THE API QUERY TAKES PLACE\n",
    "        # classification= \"English\"\n",
    "        print(f\"--------Classification is: {classification}\")\n",
    "\n",
    "        # split the languages into a list, since 'classification' may be a string with languages separated by commas\n",
    "        classification= classification.split(\",\")\n",
    "        # add each language to the set of languages associated with the conversation\n",
    "        for language in classification:\n",
    "            languages.add(language)\n",
    "\n",
    "        # print out the set of languages associated with the conversation data point\n",
    "        print(f\"--------The language(s) used in data point {i} are: {languages}\")\n",
    "\n",
    "        # associate the languages with the conversation data point in a new column\n",
    "        df.loc[i, \"post_working_language_actual\"]= \", \".join(map(str, languages))\n",
    "\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"----Data point {i} already has a working language classification!\")\n",
    "        \n",
    "# Specify the path where you want to save the CSV file\n",
    "file_path = 'conv_sample_posts.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "print(f'DataFrame has been saved to {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
