{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac213cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df839ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download punkt only once\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04ae202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr. Lu's API key: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2eb160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2964fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"conv_sample_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db51337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the API key\n",
    "openai.api_key= \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8276c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_working_language_prompt(post):\n",
    "    \"\"\"\n",
    "    Input: text string\n",
    "    Output: prompt containing the text string requesting classification\n",
    "    \"\"\"\n",
    "    # embed a (possibly truncated) post from a conversation inside a prompt that will be used to query the ChatGPT API\n",
    "    prompt= f'What natural language(s) are present in this post: \"{post}\". Please reply with the language(s) separated by commas and no additional commentary or punctuation. If the language is Chinese, please specify either \"Chinese Simplified\" or \"Chinese Traditional\".'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bd0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(post):\n",
    "    \"\"\"\n",
    "    This function performs the ChatGPT API query\n",
    "    Input: text string\n",
    "    Output: classification as a string, with commas separating languages\n",
    "    \"\"\"\n",
    "    # get the response, which is a OpenAIObject containing a JSON string\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\", \n",
    "      messages=[{\"role\": \"user\", \"content\": get_working_language_prompt(post)}]\n",
    "    )\n",
    "    \n",
    "    # get the 'content' value from the object, which contains the language classification\n",
    "    classification = response.choices[0].message.content\n",
    "\n",
    "    # return the classification, which is a string that may contain more than one language, separated by commas\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf11e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_length(conversation_id):\n",
    "    \"\"\"\n",
    "    Get the total number of posts given a conversation_id\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include only rows with the given conversation_id\n",
    "    filtered_df = df[df['conversation_id'] == conversation_id]\n",
    "    \n",
    "    # Get the total number of posts for the conversation_id\n",
    "    total_posts = len(filtered_df)\n",
    "    \n",
    "    return total_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f807fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_post(post, n):\n",
    "    \"\"\"\n",
    "    Truncate a string to a maximum number of tokens (n)\n",
    "    \"\"\"\n",
    "    # Tokenize the input string into words\n",
    "    words = word_tokenize(post)\n",
    "    \n",
    "    # Select the first n tokens\n",
    "    truncated_tokens = words[:n]\n",
    "    \n",
    "    # Join the selected tokens back into a string\n",
    "    truncated_post = ' '.join(truncated_tokens)\n",
    "    \n",
    "    return truncated_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47eec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Examining data point 0, with conversation_id 0\n",
      "----Data point 0 already has a working language classification!\n",
      "• Examining data point 1, with conversation_id 1\n",
      "----Data point 1 already has a working language classification!\n",
      "• Examining data point 2, with conversation_id 1\n",
      "----Data point 2 already has a working language classification!\n",
      "• Examining data point 3, with conversation_id 1\n",
      "----Data point 3 already has a working language classification!\n",
      "• Examining data point 4, with conversation_id 1\n",
      "----Data point 4 already has a working language classification!\n",
      "• Examining data point 5, with conversation_id 1\n",
      "----Data point 5 already has a working language classification!\n",
      "• Examining data point 6, with conversation_id 2\n",
      "----Data point 6 already has a working language classification!\n",
      "• Examining data point 7, with conversation_id 2\n",
      "----Data point 7 already has a working language classification!\n",
      "• Examining data point 8, with conversation_id 2\n",
      "----Data point 8 already has a working language classification!\n",
      "• Examining data point 9, with conversation_id 2\n",
      "----Data point 9 already has a working language classification!\n",
      "• Examining data point 10, with conversation_id 3\n",
      "----Data point 10 is part of a conversation of length 20\n",
      "--------Post content: `` Ca n't Rename , no element found '' on anything I try to rename\n",
      "--------Getting the language classification...\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-zO56g***************************************6J0H. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# get the language classification for the text\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------Getting the language classification...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m classification\u001b[38;5;241m=\u001b[39m \u001b[43mget_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncated_post\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <- HERE IS WHERE THE API QUERY TAKES PLACE\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# classification= \"English\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------Classification is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassification\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mget_classification\u001b[0;34m(post)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis function performs the ChatGPT API query\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mInput: text string\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mOutput: classification as a string, with commas separating languages\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# get the response, which is a OpenAIObject containing a JSON string\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_working_language_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# get the 'content' value from the object, which contains the language classification\u001b[39;00m\n\u001b[1;32m     14\u001b[0m classification \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-zO56g***************************************6J0H. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "# iterate through a range of conversation data points\n",
    "for i in range(100):\n",
    "    \n",
    "    conversation_id= df.at[i, 'conversation_id']\n",
    "    print(f\"• Examining data point {i}, with conversation_id {conversation_id}\")\n",
    "    \n",
    "    if pd.isna(df['post_working_language'].iloc[i]):\n",
    "\n",
    "        # see how long the conversation is\n",
    "        conversation_length= get_conversation_length(conversation_id)\n",
    "        print(f\"----Data point {i} is part of a conversation of length {conversation_length}\")\n",
    "\n",
    "        # initialize a set to store the languages associated with the post\n",
    "        languages= set()\n",
    "\n",
    "        # get the post content\n",
    "        post= df.at[i, 'post']\n",
    "        # truncate the post\n",
    "        truncated_post= truncate_post(post, 25)\n",
    "\n",
    "        # print out the truncated post\n",
    "        print(f\"--------Post content: {truncated_post}\")\n",
    "\n",
    "        # get the language classification for the text\n",
    "        print(f\"--------Getting the language classification...\")\n",
    "        classification= get_classification(truncated_post) # <- HERE IS WHERE THE API QUERY TAKES PLACE\n",
    "        # classification= \"English\"\n",
    "        print(f\"--------Classification is: {classification}\")\n",
    "\n",
    "        # split the languages into a list, since 'classification' may be a string with languages separated by commas\n",
    "        classification= classification.split(\",\")\n",
    "        # add each language to the set of languages associated with the conversation\n",
    "        for language in classification:\n",
    "            languages.add(language)\n",
    "\n",
    "        # print out the set of languages associated with the conversation data point\n",
    "        print(f\"--------The language(s) used in data point {i} are: {languages}\")\n",
    "\n",
    "        # associate the languages with the conversation data point in a new column\n",
    "        df.loc[i, \"post_working_language\"]= \", \".join(map(str, languages))\n",
    "\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"----Data point {i} already has a working language classification!\")\n",
    "        \n",
    "# Specify the path where you want to save the CSV file\n",
    "file_path = 'conv_sample_posts.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "print(f'DataFrame has been saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8398c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max_rows option temporarily to display all 100 rows\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9d464",
   "metadata": {},
   "source": [
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4ee28",
   "metadata": {},
   "source": [
    "- Add embedded language prompt\n",
    "- Manually document the working languages and embedded languages\n",
    "- Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26633025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
